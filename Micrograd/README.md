

![App Screenshot](https://i.ytimg.com/vi/VMj-3S1tku0/hqdefault.jpg?sqp=-oaymwEXCNACELwBSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLChyxrlO8apEF00Y6TnKYY5Rpg8gQ)


# Micrograd 

In this ive made a simple neural network in which ive done forward propagation and backward propagation using Gradient Descent


## Lessons Learned


1.  kickoff the understanding of the atomic pieces of the neural net: operations.
2.  see how to lay out the expression and backpropogate through them!
3.  How to perform the chain of derivations and effectively carry out the chain rule!
4.  The derivations, slopes, a change? Okay, we'll have the overview anyways!


## Deployment

To run each file you'll have to run each file individually 
```bash
  python3 {file-name}
  or 
  jupyter-notebook {file-name}
```


## Appendix

the inspiration for this project was from andrej karpathy's "Neural Networks: Zero to Hero
"


## Authors

- [@surajssamal](https://www.github.com/surajssamal)

